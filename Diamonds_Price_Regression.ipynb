{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     #handles datasets\n",
    "import seaborn as sns   #data visualization library built on top of Matplotlib\n",
    "import matplotlib.pyplot as plt     #handles gui aspect to show plotting\n",
    "from sklearn.model_selection import train_test_split # sklearn imports that manage regresion components\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "df = pd.read_csv('diamonds.csv')\n",
    "\n",
    "#QUESTION 1\n",
    "print(\"QUESTION 1\")\n",
    "print(\"\\n\")\n",
    "print(\"table before changes\",df.shape)  # for before\n",
    "print(\"check table for duplicates\")\n",
    "print(\"sum of duplicates\",df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# remove column x, y and z as they are irrelevant\n",
    "df= df.drop(['x', 'y', 'z'], axis=1)\n",
    "\n",
    "print(\"check for any missing data in the dataset\")\n",
    "print(df.isna().any())\n",
    "print(\"dataset returns null so dataset is complete\")\n",
    "\n",
    "#using the inter Quartile range method under box plot, detect outliers to remove\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['price'] < lower) | (df['price'] > upper)]\n",
    "\n",
    "print(\"\\nTable for outliers\")\n",
    "print(outliers.head())\n",
    "\n",
    "#dropping the outliers identified\n",
    "df = df.drop([23820, 23821, 23822, 23823, 23824], axis=0)\n",
    "\n",
    "print(\"\\ncheck the table after\")\n",
    "print(df.shape)  # for after\n",
    "\n",
    "\n",
    "#QUESTION 2\n",
    "print(\"QUESTION 2\")\n",
    "#bins- is used to divide/groups the vlaues into a set number of intervals\n",
    "#kde- is used to add a curve to the graph that makes it easier to see how data is skewed\n",
    "\n",
    "#Insight 1: histogram of price\n",
    "sns.histplot(df['price'], bins=30, kde=True)\n",
    "plt.title('Distribution of Diamond Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#Insight 2: histogram of carat\n",
    "sns.histplot(df['carat'], bins=30, kde=True)\n",
    "plt.title('Distribution of Diamond Carat Sizes')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#Insight 3: histogram of cut, with the various Qualities\n",
    "sns.histplot(data=df, x='price', hue='cut', bins=30, kde=True)\n",
    "plt.title('Price Distribution by Cut Quality')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "diamonds_model = df.sample(n=12500)\n",
    "print(\"random selection samplesize\",diamonds_model.shape)\n",
    "\n",
    "\n",
    "# QUESTION 3: Linear Regression Model\n",
    "print(\"\\n\")\n",
    "print(\"QUESTION 3\")\n",
    "print(\"\\n\")\n",
    "#Choose features and target\n",
    "X = diamonds_model.drop('price', axis=1)\n",
    "y = diamonds_model['price']\n",
    "\n",
    "#Convert categorical columns into numbers\n",
    "#get_dummies converts categorical variables into numerical format\n",
    "#drop first removes the first category to avoid redundancy\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "#Split data into train and test sets\n",
    "#this splits data for the machine to learn from one and test from the other\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Create and train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predict using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Measure accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# QUESTION 4\n",
    "print(\"QUESTION 4\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# selecting continuous variables\n",
    "continuousV = ['carat', 'depth', 'table']\n",
    "X = diamonds_model[continuousV]\n",
    "y = diamonds_model['price']\n",
    "\n",
    "#use PCA to reduce to 2 main features\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Split and train data again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2)\n",
    "\n",
    "pca_model = LinearRegression()\n",
    "pca_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = pca_model.predict(X_test)\n",
    "r2_pca = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"PCA + Linear Regression Results:\")\n",
    "print(\"R-squared:\", r2_pca)\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "#pca.explained_variance_ratio_= shows how much of the total data  (variance) is captured by each components.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
